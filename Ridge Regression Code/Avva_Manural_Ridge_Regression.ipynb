{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UzqBiCh2uzQJ"
   },
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OyK1BDDqu43j"
   },
   "outputs": [],
   "source": [
    "# locate the directory\n",
    "DIRECTORY = \"/home/akira/MoBI/cpcst_hopkins/\"\n",
    "arr = os.listdir(DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6LRG3Ckqu3UL"
   },
   "outputs": [],
   "source": [
    "def pre_process(subject,size):\n",
    "    # The list of columns to be dropped\n",
    "    drop_ls = [\n",
    "    \"expected_time\",\n",
    "    \"flip_time\",\n",
    "    \"stim_pos\",\n",
    "    \"user_pos\",\n",
    "    \"lambda_val\",\n",
    "    \"change_rate_x\",\n",
    "    ]\n",
    "\n",
    "    # the feature matrix in array form\n",
    "    X = subject.drop(columns=drop_ls).to_numpy()\n",
    "    #print(\"The shape of X:\", X.shape)\n",
    "    y_pos_dif = (subject[\"user_pos\"].to_numpy() - subject[\"stim_pos\"].to_numpy())\n",
    "    y = y_pos_dif\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X[:size], y[:size], test_size=0.2, random_state=23)  # only 100 samples are used here\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gxoQydvj1Eii"
   },
   "outputs": [],
   "source": [
    "class RidgeRegression:\n",
    "    def __init__(self, alpha=1.0, lr=0.01, n_iterations=1000):\n",
    "        \"\"\"\n",
    "        Ridge Regression model with L2 regularization.\n",
    "\n",
    "        Parameters:\n",
    "        alpha : float\n",
    "            Regularization strength.\n",
    "        lr : float\n",
    "            Learning rate for gradient descent.\n",
    "        n_iterations : int\n",
    "            Number of iterations for training.\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.lr = lr\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def _initialize_parameters(self, n_features):\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0.0\n",
    "\n",
    "    def _compute_cost(self, X, y):\n",
    "        n_samples = len(X)\n",
    "        y_pred = [self.bias + sum(self.weights[j] * X[i][j] for j in range(len(self.weights))) for i in range(n_samples)]\n",
    "        mse = (1 / (2 * n_samples)) * sum((y_pred[i] - y[i]) ** 2 for i in range(n_samples))\n",
    "        l2_penalty = (self.alpha / (2 * n_samples)) * sum(w ** 2 for w in self.weights)\n",
    "        return mse + l2_penalty\n",
    "\n",
    "    def _compute_gradients(self, X, y):\n",
    "        \"\"\"\n",
    "        Compute gradients of weights and bias for gradient descent, element-wise.\n",
    "        \"\"\"\n",
    "        n_samples = len(X)\n",
    "        dw = [0.0] * len(self.weights)\n",
    "        db = 0.0\n",
    "\n",
    "        # Calculate predictions and compute gradients\n",
    "        for i in range(n_samples):\n",
    "            y_pred_i = self.bias + sum(self.weights[j] * X[i][j] for j in range(len(self.weights)))\n",
    "            error = y_pred_i - y[i]\n",
    "\n",
    "            # Update the gradient for bias\n",
    "            db += error / n_samples\n",
    "\n",
    "            # Update the gradient for each weight separately\n",
    "            for j in range(len(self.weights)):\n",
    "                dw[j] += (X[i][j] * error / n_samples) + (self.alpha / n_samples) * self.weights[j]\n",
    "\n",
    "        return dw, db\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_features = len(X[0])\n",
    "        self._initialize_parameters(n_features)\n",
    "\n",
    "        for i in range(self.n_iterations):\n",
    "            dw, db = self._compute_gradients(X, y)\n",
    "            for j in range(len(self.weights)):\n",
    "                self.weights[j] -= self.lr * dw[j]\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self.bias + sum(self.weights[j] * x[j] for j in range(len(self.weights))) for x in X]\n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        ss_res = sum((y[i] - y_pred[i]) ** 2 for i in range(len(y)))\n",
    "        y_mean = sum(y) / len(y)\n",
    "        ss_tot = sum((y[i] - y_mean) ** 2 for i in range(len(y)))\n",
    "        r2_score = 1 - (ss_res / ss_tot)\n",
    "        return r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "6zPUZ2Ey2KNO"
   },
   "outputs": [],
   "source": [
    "def cross_validate_ridge(X, y, alpha_values, k=5, lr=0.01, n_iterations=1000):\n",
    "    \"\"\"\n",
    "    Perform K-Fold Cross-Validation to select the best alpha for Ridge Regression.\n",
    "\n",
    "    Parameters:\n",
    "    X : numpy.ndarray\n",
    "        Feature matrix.\n",
    "    y : numpy.ndarray\n",
    "        Target vector.\n",
    "    alpha_values : list of float\n",
    "        List of alpha values to try.\n",
    "    k : int\n",
    "        Number of folds for K-Fold Cross-Validation.\n",
    "    lr : float\n",
    "        Learning rate for gradient descent.\n",
    "    n_iterations : int\n",
    "        Number of iterations for training.\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        The best alpha value based on average cross-validation score.\n",
    "    \"\"\"\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    best_alpha = None\n",
    "    best_score = float('inf')\n",
    "\n",
    "    for alpha in alpha_values:\n",
    "        model = RidgeRegression(alpha=alpha, lr=lr, n_iterations=n_iterations)\n",
    "        fold_scores = []\n",
    "\n",
    "        for train_index, test_index in kfold.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            mse = np.mean((y_test - y_pred) ** 2)\n",
    "            fold_scores.append(mse)\n",
    "\n",
    "        average_score = np.mean(fold_scores)\n",
    "\n",
    "        if average_score < best_score:\n",
    "            best_score = average_score\n",
    "            best_alpha = alpha\n",
    "\n",
    "        print(f\"Alpha: {alpha}, Average MSE: {average_score/1e177}\")\n",
    "\n",
    "    print(f\"Best alpha: {best_alpha}, with Average MSE: {best_score/1e177}\")\n",
    "    return best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "AYmQdadQ2X6B"
   },
   "outputs": [],
   "source": [
    "subject = pd.read_csv(DIRECTORY + arr[0])\n",
    "size = subject.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "ZEPm9gAq2X2p"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = pre_process(subject,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "LKJ8RwDb2Xzq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model R² Score: -0.02390113533304817\n"
     ]
    }
   ],
   "source": [
    "model1 = RidgeRegression(n_iterations=10)\n",
    "model1.fit(X_train, y_train)\n",
    "print(\"Model R² Score:\", model1.score(X_test, y_test)/1e180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "nPhLHj0A2Nzh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01, Average MSE: 0.09603428854446681\n",
      "Alpha: 0.1, Average MSE: 0.09603428854567383\n",
      "Alpha: 1, Average MSE: 0.0960342885577439\n",
      "Alpha: 10, Average MSE: 0.0960342886784361\n",
      "Alpha: 100, Average MSE: 0.09603428988536529\n",
      "Best alpha: 0.01, with Average MSE: 0.09603428854446681\n",
      "Model R² Score: -0.02390113532974407\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "# X, y should be your features and target arrays\n",
    "alpha_values = [0.01, 0.1, 1, 10, 100]  # Define a range of alpha values to try\n",
    "best_alpha = cross_validate_ridge(X_train, y_train, alpha_values, k=5, lr=0.01, n_iterations=10)\n",
    "\n",
    "# Train the final model with the best alpha\n",
    "model2 = RidgeRegression(alpha=best_alpha, lr=0.01, n_iterations=10)\n",
    "model2.fit(X_train, y_train)\n",
    "z =  model2.score(X_test, y_test)/1e180\n",
    "print(\"Model R² Score:\", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.02390113532974407)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_alpha"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
